{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factual Hallucination mitigation\n",
    "\n",
    "## Experiment 1: Increasing context specificity\n",
    "\n",
    "Evaluate fine-tuned model(s) with an increasing specificity in the prompt. Do we see a difference on LMs fine-tuned on XSum? Do we see a difference on LMs that are trained to follow instructions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulius/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-07 14:40:32.837957: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-07 14:40:37.115293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/paulius/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading Named Entity Recognition Pipeline<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading Named Entity Recognition Pipeline\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading Relation Extraction Pipeline<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading Relation Extraction Pipeline\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5714285714285714</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m0.5714285714285714\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"lionel Andrés Messi is an argentine professional footballer . he has won a record six ballon d'Or awards, six european golden shoes . in 2020 he was named to the ballon dream team.\"}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metric.metrics import compute_metrics_pipeline\n",
    "\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "article = \"Lionel Andrés Messi (born 24 June 1987) is an Argentine professional footballer who plays as a forward and captains both Spanish club Barcelona and the Argentina national team. Often considered as the best player in the world and widely regarded as one of the greatest players of all time, Messi has won a record six Ballon d'Or awards, a record six European Golden Shoes, and in 2020 was named to the Ballon d'Or Dream Team.\"\n",
    "\n",
    "# Important! For logging results\n",
    "MODEL_NAME = \"t5-small\"\n",
    "# TODO: Change the summarizer model to our own!\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
    "summarizer(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m1.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m1.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m1.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m1.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m1.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fact Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fact Score: \u001b[1;36m1.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m pred_summary \u001b[39m=\u001b[39m summarizer(prompt)[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msummary_text\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[39m# print(f\"Prompt:\\n{prompt}\")\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# print(f\"Summary:\\n{pred_summary}\")\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m metric_res \u001b[39m=\u001b[39m compute_metrics_pipeline([article], [pred_summary])\n\u001b[1;32m     19\u001b[0m \u001b[39m# for metric, val in metric_res.items():\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m#     print(f\"{metric}: {val}\", end=\" \")\u001b[39;00m\n\u001b[1;32m     21\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00md[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mp_idx\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mmetric_res[\u001b[39m'\u001b[39m\u001b[39mqags\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mmetric_res[\u001b[39m'\u001b[39m\u001b[39mrouge\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mmetric_res[\u001b[39m'\u001b[39m\u001b[39mtriples\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mmetric_res[\u001b[39m'\u001b[39m\u001b[39mbleurt\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mmetric_res[\u001b[39m'\u001b[39m\u001b[39msummac\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mmetric_res[\u001b[39m'\u001b[39m\u001b[39mensemble\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/dl4nlp-text-summarization/metric/metrics.py:71\u001b[0m, in \u001b[0;36mcompute_metrics_pipeline\u001b[0;34m(articles, summaries, device)\u001b[0m\n\u001b[1;32m     69\u001b[0m rouge_scores\u001b[39m.\u001b[39mappend(rouge)\n\u001b[1;32m     70\u001b[0m \u001b[39m# BERT = factsumm.calculate_bert_score(article, summary)\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m facts \u001b[39m=\u001b[39m factsumm\u001b[39m.\u001b[39;49mextract_facts(article, summary)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]   \u001b[39m# Take only the score\u001b[39;00m\n\u001b[1;32m     72\u001b[0m facts \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     73\u001b[0m fact_scores\u001b[39m.\u001b[39mappend(facts)\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/factsumm/__init__.py:182\u001b[0m, in \u001b[0;36mFactSumm.extract_facts\u001b[0;34m(self, source, summary, verbose)\u001b[0m\n\u001b[1;32m    179\u001b[0m summary_lines \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_segment(summary)\n\u001b[1;32m    181\u001b[0m \u001b[39m# extract per-line entities\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m source_ents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mner(source_lines)\n\u001b[1;32m    183\u001b[0m summary_ents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mner(summary_lines)\n\u001b[1;32m    185\u001b[0m \u001b[39m# extract entity-based triple: (head, relation, tail)\u001b[39;00m\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/factsumm/utils/level_entity.py:32\u001b[0m, in \u001b[0;36mload_ner.<locals>.extract_entities\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences:\n\u001b[1;32m     31\u001b[0m     sentence \u001b[39m=\u001b[39m Sentence(sentence)\n\u001b[0;32m---> 32\u001b[0m     ner\u001b[39m.\u001b[39;49mpredict(sentence)\n\u001b[1;32m     33\u001b[0m     \u001b[39m# line_result = sentence.to_dict(tag_type=\"ner\")\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     line_result \u001b[39m=\u001b[39m sentence\u001b[39m.\u001b[39mget_spans(\u001b[39m'\u001b[39m\u001b[39mner\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/flair/models/sequence_tagger_model.py:483\u001b[0m, in \u001b[0;36mSequenceTagger.predict\u001b[0;34m(self, sentences, mini_batch_size, return_probabilities_for_all_classes, verbose, label_name, return_loss, embedding_storage_mode, force_token_predictions)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[39m# get features from forward propagation\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m sentence_tensor, lengths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_tensors(batch)\n\u001b[1;32m    484\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(sentence_tensor, lengths)\n\u001b[1;32m    486\u001b[0m \u001b[39m# remove previously predicted labels of this type\u001b[39;00m\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/flair/models/sequence_tagger_model.py:287\u001b[0m, in \u001b[0;36mSequenceTagger._prepare_tensors\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     sentences \u001b[39m=\u001b[39m data_points\n\u001b[0;32m--> 287\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings\u001b[39m.\u001b[39;49membed(sentences)\n\u001b[1;32m    289\u001b[0m \u001b[39m# make a zero-padded tensor for the whole sentence\u001b[39;00m\n\u001b[1;32m    290\u001b[0m lengths, sentence_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_padded_tensor_for_batch(sentences)\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/flair/embeddings/token.py:101\u001b[0m, in \u001b[0;36mStackedEmbeddings.embed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m     98\u001b[0m     sentences \u001b[39m=\u001b[39m [sentences]\n\u001b[1;32m    100\u001b[0m \u001b[39mfor\u001b[39;00m embedding \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings:\n\u001b[0;32m--> 101\u001b[0m     embedding\u001b[39m.\u001b[39;49membed(sentences)\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/flair/embeddings/base.py:49\u001b[0m, in \u001b[0;36mEmbeddings.embed\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m     46\u001b[0m     data_points \u001b[39m=\u001b[39m [data_points]\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_everything_embedded(data_points):\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_embeddings_internal(data_points)\n\u001b[1;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m data_points\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/flair/embeddings/token.py:819\u001b[0m, in \u001b[0;36mFlairEmbeddings._add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    816\u001b[0m end_marker \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    818\u001b[0m \u001b[39m# get hidden states from language model\u001b[39;00m\n\u001b[0;32m--> 819\u001b[0m all_hidden_states_in_lm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlm\u001b[39m.\u001b[39;49mget_representation(\n\u001b[1;32m    820\u001b[0m     text_sentences, start_marker, end_marker, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchars_per_chunk\n\u001b[1;32m    821\u001b[0m )\n\u001b[1;32m    823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfine_tune:\n\u001b[1;32m    824\u001b[0m     all_hidden_states_in_lm \u001b[39m=\u001b[39m all_hidden_states_in_lm\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/flair/models/language_model.py:161\u001b[0m, in \u001b[0;36mLanguageModel.get_representation\u001b[0;34m(self, strings, start_marker, end_marker, chars_per_chunk)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m batches:\n\u001b[1;32m    160\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m     rnn_output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(batch, hidden, decode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    162\u001b[0m     output_parts\u001b[39m.\u001b[39mappend(rnn_output)\n\u001b[1;32m    164\u001b[0m \u001b[39m# concatenate all chunks to make final output\u001b[39;00m\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/flair/models/language_model.py:89\u001b[0m, in \u001b[0;36mLanguageModel.forward\u001b[0;34m(self, input, hidden, ordered_sequence_lengths, decode)\u001b[0m\n\u001b[1;32m     87\u001b[0m     hidden \u001b[39m=\u001b[39m (h,)\n\u001b[1;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(emb, hidden)\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj(output)\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prompt1 = \"Summarize the following text: \"\n",
    "prompt2 = \"Using the exact wording of the text, summarize the following text: \"\n",
    "prompt3 = \"Summarize the following text by including direct quotes where they are essential to convey the author's message accurately: \"\n",
    "prompts = [prompt1, prompt2, prompt3]\n",
    "dataset = load_dataset(\"xsum\", split=\"test\")\n",
    "\n",
    "with open(\"exp1-results.csv\", \"w\") as f:\n",
    "    f.write(\"xsum_id,prompt_id,qags,rouge,triples,bleurt,summac,ensemble\\n\")\n",
    "    for idx, d in enumerate(dataset):\n",
    "        if idx == 10:\n",
    "            break\n",
    "        article = d[\"document\"]\n",
    "        for p_idx, prompt in enumerate(prompts):\n",
    "            # Add the actual article to the prompt\n",
    "            prompt += article\n",
    "            # Summarize the article\n",
    "            pred_summary = summarizer(prompt)[0]['summary_text']\n",
    "            print(f\"Prompt:\\n{prompt}\")\n",
    "            print(f\"Summary:\\n{pred_summary}\")\n",
    "            metric_res = compute_metrics_pipeline([article], [pred_summary])\n",
    "            print(f\"{d['id']},{p_idx},{metric_res['qags'][0]},{metric_res['rouge'][0]},{metric_res['triples'][0]},{metric_res['bleurt'][0]},{metric_res['summac'][0]},{metric_res['ensemble'][0]}\\n\")\n",
    "            # Write metrics to csv file\n",
    "            f.write(f\"{d['id']},{p_idx},{metric_res['qags'][0]},{metric_res['rouge'][0]},{metric_res['triples'][0]},{metric_res['bleurt'][0]},{metric_res['summac'][0]},{metric_res['ensemble'][0]}\\n\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "exp1_df = pd.read_csv(\"exp1-results-test.csv\")\n",
    "# Get all the results for separate prompts\n",
    "p1 = exp1_df[exp1_df[\"prompt_id\"] == 0]\n",
    "p2 = exp1_df[exp1_df[\"prompt_id\"] == 1]\n",
    "p3 = exp1_df[exp1_df[\"prompt_id\"] == 2]\n",
    "p1_mean = p1.mean()\n",
    "p12_mean = p1.mean()\n",
    "p1_mean = p1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Chain-of-verification\n",
    "\n",
    "1. Ask LLM $M_S$ to summarize a text, receive response $resp$\n",
    "2. Generate questions from $resp$ using a question-generating model $M_{QG}$\n",
    "3. Ask LLM $M_S$ to answer the generated questions\n",
    "4. Create a new prompt that is comprised of the generated questions by $M_{QG}$, the answers by $M_S$, and the original prompt to summarize a text\n",
    "5. Receive a verified response $resp_v$\n",
    "\n",
    "> Do we need to fine-tune the model on question answering as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running - modify factsumm!\n",
    "\n",
    "So, in order for this to work, we need to generate questions. Factsumm has a way to do this, so it's easiest to just use its implementation. However, you need to add the following function to the `FactSumm` class code in your virtual environment:\n",
    "\n",
    "```\n",
    "def extract_questions(\n",
    "        self,\n",
    "        summary: str,\n",
    "        summary_ents: List = None,\n",
    "        verbose: bool = False,\n",
    "        device: str = \"cpu\",\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract Questions from Question Generation module\n",
    "\n",
    "            See also https://arxiv.org/abs/2004.04228\n",
    "\n",
    "        Args:\n",
    "            summary (str): generated summary\n",
    "            summary_ents (List, optional): named entities extracted from source. Defaults to None.\n",
    "            verbose (bool, optional): print verbose option. Defaults to False.\n",
    "            device (str): device info\n",
    "\n",
    "        \"\"\"\n",
    "        if isinstance(self.qg, str):\n",
    "            self.qg = load_qg(self.qg, device)\n",
    "\n",
    "        if isinstance(self.ner, str):\n",
    "            self.ner = load_ner(self.ner, device)\n",
    "\n",
    "        summary_lines = self._segment(summary)\n",
    "        if summary_ents is None:\n",
    "            summary_ents = self.ner(summary_lines)\n",
    "\n",
    "        # If no entities (answers) are found, no questions can be generated\n",
    "        if len(summary_ents) == 0:\n",
    "            return []\n",
    "\n",
    "        summary_lines = self._segment(summary)\n",
    "        summary_qas = self.qg(summary_lines, summary_ents)\n",
    "        questions = [qa_pair[\"question\"] for qa_pair in summary_qas]\n",
    "\n",
    "        return questions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulius/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-08 09:34:48.657695: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-08 09:34:51.092003: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-08 09:34:56.070225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/paulius/personal/Pauliaus/Lectures/Amsterdam/year2/semester1/deep-learning-for-nlp/assignments/.venv/lib/python3.8/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"lionel Andrés Messi is an argentine professional footballer . he has won a record six ballon d'Or awards, six european golden shoes . in 2020 he was named to the ballon dream team.\"}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from metric.metrics import compute_metrics_pipeline\n",
    "import metric.metrics\n",
    "\n",
    "# Important! For logging results\n",
    "MODEL_NAME = \"t5-small\"\n",
    "# TODO: Change to our trained models!!\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
    "\n",
    "article = \"Lionel Andrés Messi (born 24 June 1987) is an Argentine professional footballer who plays as a forward and captains both Spanish club Barcelona and the Argentina national team. Often considered as the best player in the world and widely regarded as one of the greatest players of all time, Messi has won a record six Ballon d'Or awards, a record six European Golden Shoes, and in 2020 was named to the Ballon d'Or Dream Team.\"\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "summarizer(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mxsum\u001b[39m\u001b[39m\"\u001b[39m, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m BASE_PROMPT \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSummarize the following text: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchain_of_verification\u001b[39m(baseline_summary: \u001b[39mstr\u001b[39m, prompt: \u001b[39mstr\u001b[39m, summ_model):\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Generate questions based on baseline response\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"xsum\", split=\"test\")\n",
    "BASE_PROMPT = \"Summarize the following text: \"\n",
    "\n",
    "\n",
    "def chain_of_verification(baseline_summary: str, prompt: str, summ_model):\n",
    "    # Generate questions based on baseline response\n",
    "    questions = metric.metrics.factsumm.extract_questions(baseline_summary, verbose=False, device=device)\n",
    "\n",
    "    # Make a modified prompt based on the answers to generated questions    \n",
    "    # and their answers\n",
    "    verified_prompt = \"\"\n",
    "    for question in questions:\n",
    "        # TODO: is this correct? Or should we have fine-tuned our summarization model on question-answering?\n",
    "        resp_q = summ_model(question)[0]['summary_text']\n",
    "        verified_prompt += f\"{question}\\n{resp_q}\\n\"\n",
    "    verified_prompt += f\"\\n{prompt}\"\n",
    "\n",
    "    # Get verified response\n",
    "    resp_v = summ_model(verified_prompt)[0]['summary_text']\n",
    "    return verified_prompt, resp_v\n",
    "\n",
    "\n",
    "with open(f\"exp2-results-{MODEL_NAME}.csv\", \"w\") as f:\n",
    "    f.write(\"xsum_id,qags,rouge,triples,bleurt,summac,ensemble\\n\")\n",
    "    for idx, d in enumerate(dataset):\n",
    "        # Early stopping for testing\n",
    "        # if idx == 3:\n",
    "        #     break\n",
    "        article = d[\"document\"]\n",
    "\n",
    "        # Add the actual article to the prompt\n",
    "        prompt = f\"{BASE_PROMPT}{article}\"\n",
    "        # Summarize the article\n",
    "        pred_summary = summarizer(prompt)[0][\"summary_text\"]\n",
    "\n",
    "        verified_prompt, verified_pred_summary = chain_of_verification(\n",
    "            pred_summary, prompt, summarizer\n",
    "        )\n",
    "\n",
    "        print(f\"Prompt:\\n{verified_prompt}\")\n",
    "        print(f\"Summary:\\n{verified_pred_summary}\")\n",
    "\n",
    "        metric_res = compute_metrics_pipeline([article], [verified_pred_summary])\n",
    "        print(\n",
    "            f\"{d['id']},\"\n",
    "            f\"{metric_res['qags'][0]},\"\n",
    "            f\"{metric_res['rouge'][0]},\"\n",
    "            f\"{metric_res['triples'][0]},\"\n",
    "            f\"{metric_res['bleurt'][0]},\"\n",
    "            f\"{metric_res['summac'][0]},\"\n",
    "            f\"{metric_res['ensemble'][0]}\\n\"\n",
    "        )\n",
    "        # Write metrics to csv file\n",
    "        f.write(\n",
    "            f\"{d['id']},\"\n",
    "            f\"{metric_res['qags'][0]},\"\n",
    "            f\"{metric_res['rouge'][0]},\"\n",
    "            f\"{metric_res['triples'][0]},\"\n",
    "            f\"{metric_res['bleurt'][0]},\"\n",
    "            f\"{metric_res['summac'][0]},\"\n",
    "            f\"{metric_res['ensemble'][0]}\\n\"\n",
    "        )\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
