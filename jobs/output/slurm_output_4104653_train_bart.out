2023-10-11 14:11:00.579120: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-10-11 14:11:00.872220: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-11 14:11:03.508156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-11 14:11:19.811084: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
WARNING:datasets.builder:Found cached dataset xsum (/home/scur0666/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)
WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at /home/scur0666/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71/cache-cb28695fbc0c5af7.arrow and /home/scur0666/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71/cache-4d5b51f626b26a3d.arrow
WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/scur0666/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71/cache-6aa57b2f74234a07.arrow
WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/scur0666/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71/cache-d38321f081a8b922.arrow
WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/scur0666/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71/cache-c19112ff2997dc19.arrow
wandb: Currently logged in as: etatar-atdamen (ribfrac_team7). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.11
wandb: Run data is saved locally in /gpfs/home1/scur0666/dl4nlp-text-summarization/wandb/run-20231011_141137-xr5cdt77
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-pyramid-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ribfrac_team7/huggingface
wandb: üöÄ View run at https://wandb.ai/ribfrac_team7/huggingface/runs/xr5cdt77
<All keys matched successfully>
model facebook/bart-base
Size of train set 172301
Size of eval set 43076
{'loss': 3.2961, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.17}
Traceback (most recent call last):
  File "/home/scur0666/.conda/envs/DL4NLP/lib/python3.11/site-packages/torch/serialization.py", line 441, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/home/scur0666/.conda/envs/DL4NLP/lib/python3.11/site-packages/torch/serialization.py", line 668, in _save
    zip_file.write_record(name, storage.data_ptr(), num_bytes)
RuntimeError: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/1: file write failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Error in sys.excepthook:
object address  : 0x14bd11d5cbc0
object refcount : 1
object type     : 0x872280
object type name: OSError
object repr     : 


slurmstepd: error: *** JOB 4104653 ON gcn34 CANCELLED AT 2023-10-11T16:10:48 ***
slurmstepd: error: container_p_join: setns failed for /slurm/4104653/.ns: Invalid argument
slurmstepd: error: container_g_join(4104653): Invalid argument

JOB STATISTICS
==============
Job ID: 4104653
Cluster: snellius
User/Group: scur0666/scur0666
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:01
CPU Efficiency: 0.00% of 1-12:01:12 core-walltime
Job Wall-clock time: 02:00:04
Memory Utilized: 6.41 GB
Memory Efficiency: 6.56% of 97.66 GB
